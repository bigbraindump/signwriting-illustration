{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This script is used to calculate the clip score for FSW images (References) and generated images (Candidates)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports and libraries\n",
    "import numpy as np\n",
    "\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "from PIL import Image, ImageDraw\n",
    "from IPython.display import display, clear_output\n",
    "from signwriting.visualizer.visualize import signwriting_to_image\n",
    "from signwriting_evaluation.metrics.clip import SignWritingCLIPScore, signwriting_to_clip_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper function\n",
    "\n",
    "def create_side_by_side_comparison(reference_image, candidate_image, score, ref_stem, cand_key):\n",
    "    side_by_side = Image.new('RGB', (reference_image.width * 2, reference_image.height), (255, 255, 255))\n",
    "    \n",
    "    side_by_side.paste(reference_image, (0, 0))\n",
    "    side_by_side.paste(candidate_image, (reference_image.width, 0))\n",
    "    \n",
    "    draw = ImageDraw.Draw(side_by_side)\n",
    "    draw.text((0, 0), f\"{score:.3f}\", fill=(255, 0, 0))\n",
    "    draw.text((0, 20), f\"Ref: {ref_stem}\", fill=(255, 0, 0))\n",
    "    draw.text((reference_image.width, 0), f\"Cand: {cand_key}\", fill=(255, 0, 0))\n",
    "    \n",
    "    return side_by_side\n",
    "\n",
    "\n",
    "def manual_review(reference_img, candidate_img, score, ref_stem, cand_key):\n",
    "    while True:\n",
    "        clear_output(wait=True)\n",
    "        side_by_side = create_side_by_side_comparison(\n",
    "            reference_img,\n",
    "            candidate_img,\n",
    "            score,\n",
    "            ref_stem,\n",
    "            cand_key\n",
    "        )\n",
    "        display(side_by_side)\n",
    "        \n",
    "        response = input(\"Accept this match? (y/n): \").lower()\n",
    "        if response in ['y', 'n']:\n",
    "            return response == 'y'\n",
    "        print(\"Please enter 'y' or 'n'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load image functions\n",
    "\n",
    "def load_candidate_images(directory: Path):\n",
    "    images = {}\n",
    "    for image in tqdm(list(directory.glob('*.png'))):\n",
    "        try:\n",
    "            # binarization \n",
    "            img = Image.open(image).convert('L')\n",
    "            img = img.point(lambda x: 255 if x > 127 else 0, '1')\n",
    "            img = img.convert('L')\n",
    "            images[image.stem] = img\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {image}: {e}\")\n",
    "    return images\n",
    "\n",
    "\n",
    "def load_gold_images(directory: Path):\n",
    "    target_size = (256, 256)\n",
    "    images = {}\n",
    "    for image in tqdm(list(directory.glob('*.png'))):\n",
    "        try:\n",
    "            img = Image.open(image).convert('RGBA')\n",
    "            \n",
    "            # scale down the image\n",
    "            scale_factor = 0.42\n",
    "            max_dimension = max(img.width, img.height)\n",
    "            scale = (target_size[0] * scale_factor) / max_dimension\n",
    "            new_size = (int(img.width * scale), int(img.height * scale))\n",
    "            img = img.resize(new_size, Image.LANCZOS)\n",
    "            \n",
    "            # create white background and center the image\n",
    "            background = Image.new('RGBA', target_size, (255, 255, 255, 255))\n",
    "            offset = ((target_size[0] - new_size[0]) // 2, \n",
    "                     (target_size[1] - new_size[1]) // 2)\n",
    "            background.paste(img, offset, img)\n",
    "            \n",
    "            array = np.array(background)\n",
    "            array[array < 170] = 0\n",
    "            array[array >= 170] = 255\n",
    "            \n",
    "            images[image.stem] = Image.fromarray(array)\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {image}: {e}\")\n",
    "    return images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading candidates...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2863/2863 [00:06<00:00, 456.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading references...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|███████▏  | 2308/3192 [00:07<00:02, 299.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing glossen\\06533.png: cannot identify image file 'C:\\\\Users\\\\sarah\\\\Desktop\\\\Thesis\\\\signwriting-illustration\\\\datasets\\\\Vokabeltrainer\\\\glossen\\\\06533.png'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3192/3192 [00:09<00:00, 319.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing glossen\\09372.png: cannot identify image file 'C:\\\\Users\\\\sarah\\\\Desktop\\\\Thesis\\\\signwriting-illustration\\\\datasets\\\\Vokabeltrainer\\\\glossen\\\\09372.png'\n",
      "Candidates: 2863\n",
      "References: 3190\n",
      "\n",
      "Example loaded images:\n",
      "\n",
      "Reference 1:\n",
      "  Key: 00001\n",
      "  Image mode: RGBA\n",
      "  Image size: (256, 256)\n",
      "  Unique pixel values: [  0 255]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQAAAAEACAYAAABccqhmAAAEq0lEQVR4nO3dwW7aUBRFUVPl/3/ZHVFFLgbjJKXcvdaoalQJqTo7Dwc7l3Vd1wVI+vXqFwC8jgBAmABAmABAmABAmABAmABAmABAmABAmABAmABAmABAmABAmABAmABAmABAmABAmABAmABAmABAmABAmABAmABAmABAmABAmABAmABAmABAmABAmABAmABAmABAmABAmABAmABAmABAmABAmABAmABAmABAmABAmABAmABAmABAmABAmABAmABAmABAmABAmABAmABAmABAmABAmABAmABAmABAmABAmABAmABAmABAmABAmABAmABAmABAmABAmABAmABAmABAmABAmABAmABAmABAmABA2MerXwD/h8vl8ufP67q+8JXwLzkBQJgAQJgAQJgAQJiLgAO5oMdRTgDDfY4BbAlAgAiwRwAGcuznKAEYahsBpwBuEYDBRIBHBGC4WxEQAq4EIMA1AfYIQIS3A9wiACEiwJYAxOxFwNuEJgEIcmGQKwGI8h2fZRGANBHA3YBDOMJzhhMAT3PNYA4nAA4z+nkEYKCz7+0NvMdbAJZleTz+7dddQJxBAHjI+OcSAO4y/tkEgF3GP58AcJPxNwgAfzH+DgHgLuOfTQDYZfzzCQA3GX+DAPAX4+8QAAgTAAhzM9BAburhKCcACBMACPMWYAhX7jnDCQDCBADCBADCBADCBCDCZwO4RQACruMXAbYEYLjt6P1SDz4TgMHuDV0EWBYBGMvAOUIABjo6fpFAAIZ5dtQi0OZegCG+MuTrv3U/QY8TAIQ5AQyx/e79+UTw+Wt7f0+TEwCECQCECQCECQCECQCECQCECQCECQCECQCEXVYfB4MsJwAIEwAIEwAIEwAIEwAIEwAIEwAI80SggR49H9BHP7hyAgjyJGCunACG2Bv13rMCL5eLkwBOABM8+hVgRx4QSpN7Ad7cvaf8bgfu6cBsOQEMduZR4bQIwHCPTgW0CUCAIz57BADCBADCBCDm+nbATwFYFgEY5cgFvnufC6BHAN7cV67yGz8CMIAf9XGWTwIOcmb4/vvbnAAGOTNmp4U2ARhmXdenQyACXQLAsiwiUCUAA50dswj0CMAwXx2xCLQIwCDfNV4R6BCAIb57tCLQIAAD/NRYRWA+AXhzPz1SEZhNACBMACBMAN7cT3+W370CswnAAD81UuOfTwCG+M6xnrmfgPckAIMYLc8SgGG+GgERaRGAgc6O2Ph7BGCoZ8ds/E0CMNjRURt/lwAM92jcxt8mAAF7Izd+BCBiO3bjZ1mW5ePVL4B/x+jZcgKAMAGAMAGAMAGAMAGAMAGAMAGAMAGAMAGAMAGAMAGAMAGAMAGAMAGAMAGAMAGAMAGAMAGAMAGAMAGAMAGAMAGAMAGAMAGAMAGAMAGAMAGAMAGAMAGAMAGAMAGAMAGAMAGAMAGAMAGAMAGAMAGAMAGAMAGAMAGAMAGAMAGAMAGAMAGAMAGAMAGAMAGAMAGAMAGAMAGAMAGAMAGAMAGAMAGAMAGAMAGAMAGAMAGAMAGAMAGAMAGAMAGAMAGAMAGAMAGAMAGAMAGAMAGAMAGAMAGAMAGAMAGAMAGAMAGAsN/KC/AXNl+SCgAAAABJRU5ErkJggg==",
      "text/plain": [
       "<PIL.Image.Image image mode=RGBA size=256x256>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Reference 2:\n",
      "  Key: 00004\n",
      "  Image mode: RGBA\n",
      "  Image size: (256, 256)\n",
      "  Unique pixel values: [  0 255]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQAAAAEACAYAAABccqhmAAAFUklEQVR4nO3dS3LjNgBAwSg1978ys0ipPHEsjT4kAPF1r7UgYOIRJC37sm3b9heQ9PfsAwDmEQAIEwAIEwAIEwAIEwAIEwAIEwAIEwAIEwAIEwAIEwAIEwAIEwAIEwAIEwAIEwAIEwAIEwAIEwAIEwAIEwAIEwAIEwAIEwAIEwAIEwAIEwAIEwAIEwAIEwAIEwAIEwAIEwAIEwAIEwAIEwAIEwAIEwAIEwAIEwAIEwAIEwAIEwAIEwAIEwAIEwAIEwAIEwAIEwAIEwAIEwAIEwAIEwAIEwAIEwAIEwAIEwAIEwAIEwAIEwAIEwAIEwAIEwAIEwAIEwAIEwAIEwAIEwAIEwAIEwAIEwAIEwAI+zX7AAoul8sfP7Nt24AjWYc5WYMdwCIeWRBnURrr6i6bzB7m+4l+b6qvnz37j+ORcT4zb7zHDuAgr17lLpfLKa+Q74zrjPOxCs8ABnjkCnb9zNlPdnOxFjuAg9m+vs7cHU8ADuDKtT9zegwB2JkT9Tjmdn+eAQx2uVz+s7W9dVLfehK+6tuCR4/r9/H/NBerjevsvAbc2b1XWHtfwVb50R05Lq8Ej+UW4EOttBBWOhae4xZgoFuvtx7ZNj/z+Rm2bXt7J7DiuM7ODmCC7yf6vYXzCYv/6p1jW3lcZyYAkzwSgU9a/FevHOMnjOusBGCiexH4xMV/9cyxftK4zkgAJvtpAXzy4r/6xGMuEoAFnPW1171j37bto8d2FgKwsDMskDOM4cwEYBHfr4hnWjjfx3WmsX06AVjMWRfIGcd0BgLAMCKwHgGAMAGAMAGAMAGAMAGAMAGAMAGAMH8SbCf3vtNvil9jTo9nBzCAv2b7PHM2hgBAmADs4JGrlSva48znOALwJifiPOb+fQIAYQIAYV4DvuHVLagp/5n5HM8OAMIEAMLcArxgj6fPpv2/zOkcdgCTeIX1xVzMIwCTuFp9MRfzuAWAMDsACBMACBMACBMACBMACBMACBMACBMACBMACBMACBMACBMACPs1+wA+0e9fX/Vdqrn8LN5jB/Am32Wfx9y/TwAgTAAgTAAgTAAgTAAgzGvABZReZZXG+gnsACYrv8oqj30VAjCRBWAOZhOASZz4X8zFPAIwwa0TvnBPfGuMIjCHAAxWXvxXIrAOARjI4v8iAmsQgEEs/v8TgfkEYACL/zYRmEsADmbx/5kIzCMAB7L4HycCcwjAQX46cbdts/jvuDU/InAcATiAE3Z/5vQYArAz2/73uR0YRwB2ZPHvRwTGEICdWPz7E4HjCcAOLP7jiMCxBOAgFv9+zOVx/EWgnTlZj3GdV1f+fdkBQNhlc8mCLDsACBMACPMQ8AWjHkSd5e7MfK3LDmBhZ3jifYYxnJkAQJgAQJhnAIM8en969i2zeViLHcAAHk49z5yNIQADuJo9z5yNIQAQJgAQJgAQJgAQJgAQJgAQJgAQJgAQJgAQJgAQJgAD+L3255mzMQRgAL/X/jxzNoavAw/ihP6XeViLHQCECQCECQCE+c9AEGYHAGECAGECAGECAGECAGECAGECAGECAGECAGECAGECAGECAGECAGECAGECAGECAGECAGECAGECAGECAGECAGECAGECAGECAGECAGECAGECAGECAGECAGECAGECAGECAGECAGECAGECAGECAGECAGECAGECAGECAGECAGECAGECAGECAGECAGECAGECAGECAGECAGECAGECAGECAGECAGECAGECAGECAGECAGECAGECAGECAGECAGECAGECAGECAGECAGECAGECAGECAGECAGECAGECAGECAGECAGECAGH/AODadfHixEnbAAAAAElFTkSuQmCC",
      "text/plain": [
       "<PIL.Image.Image image mode=RGBA size=256x256>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Reference 3:\n",
      "  Key: 00006\n",
      "  Image mode: RGBA\n",
      "  Image size: (256, 256)\n",
      "  Unique pixel values: [  0 255]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQAAAAEACAYAAABccqhmAAAFjUlEQVR4nO3d23LaSBRAUWsq///LzBMpj8YYSQjU0l7rKZUqLrE5m6ZpyHS73W5fQNI/R98B4DgCAGECAGECAGECAGECAGECAGECAGECAGECAGECAGECAGECAGECAGECAGECAGECAGECAGECAGECAGECAGECAGECAGECAGECAGECAGECAGECAGECAGECAGECAGECAGECAGECAGECAGECAGECAGECAGECAGECAGECAGECAGECAGECAGECAGECAGECAGECAGECAGECAGECAGECAGECAGECAGECAGECAGECAGECAGECAGECAGECAGECAGECAGECAGECAGECAGECAGECAGECAGECAGECAGECAGECAGECAGECAGECAGECAGECAGECAGECAGECAGECAGECAGECAGECAGECAGECAGECAGECAGF/jr4DjGWapr9/vt1uB94TPsEKAMIEAMK8BAh6tMz//vdrLsd5WQHELR3qZ3HgnAQgaD7oa575f7o85zXd/Daztjyre7hcixVA2NphNvzXIwBxS4fa8F+TAPB0uA3/dQlA3DRNqzcBuQ4BYBERuCYBCJufAZgv9ed/JwLX4yRg0CuDfL+sfYFrsALg7zA/CoNhvy4HgfiPZ0eDp2kShAuxAmAVw38t9gAG4VguRxCAA+y1m/7T9YgCa9gD+LBPvJXmV8pSVgAfsHTolwzu9024R9friztYyibgIHwohyNYAbzJb8/67xri2+32v9u1GuA3AvAGRx6Z/SkCd6++h3+Wo8BCt5wA7GyE03S/nd/fGoGzDD/r2APY0QjDv+S2DTN3VgA7GXH4f3OmI72+rfh9rAB28OhAzigD9ui+GB4E4EVnH6Kz339eIwAvGP2Zf85KgDkBOLG1/8HHnrd19PWwD5uAOzriwT1/33/J5t6zo8TPLrfEHgehrEzezwpgg/k36Y627N/y2YMl3w68hpcb5yAAF7V10D4xoCIwDgFYacQH76PVxwgRsBIYmz2AFUZ+0D76DMDI9/lMh5GuygpghWffm3+0ke7L3N6rFPYhABdzj9KIMfByYDwCsMLZHqgjRuCRs/1sr8IewEJnfYBufc/9na/PH51DsCfweVYADOWsoT0rAdjoas9UR+wb2Bg8ngBwKBuDxxIACBMAhjDqW5dXJwAQJgAMxUrgs5wDYHg2BN/HCoAhWQV8hhUAwxKB97MCgDABgDAB2OhqG1N7fycg5yAAECYAC9U2pGr/3ioBWMFQcDUCAGHOAazw0zfYfH2de2Vg46/NCmCFMw86/EQAVrp6BHwYp0UAIGy6yf1m89fPZ/tRzv+DU3qsAHZ0lg01p/64E4CdGSzORABecLavtX70zG/53yUALzpbBOYMf5sA7GD0CHjm5xEB2MmoEXh0+4afry8B2NWoEZgz/Nw5B/AGzwb+3T/y327fr5vvrADe4MghM/ysYQXwAUteAmz5NbzreunwceBBjLZPQIMAfMD3Z+FPDLpnfZYSgA/7aThficL9+qZpMvisZhNwAFsH9/vlDD9bWAEMwgBzBCsACBMACBMACBMACBMACBMACBMACBMACBMACBMACBMACBMACBMACBMACBMACBMACBMACBMACBMACBMACBMACBMACBMACBMACBMACBMACBMACBMACBMACBMACBMACBMACBMACBMACBMACBMACBMACBMACBMACBMACBMACBMACBMACBMACBMACBMACBMACBMACBMACBMACBMACBMACBMACBMACBMACBMACBMACBMACBMACBMACBMACBMACBMACBMACBMACBMACBMACBMACBMACBMACBMACBMACBMACBMACBMACBMACBMACBMACBMACBMACBMACBMACBMACBMACBMACBMACBMACBMACBMACPsXwAWv4nnvgJMAAAAASUVORK5CYII=",
      "text/plain": [
       "<PIL.Image.Image image mode=RGBA size=256x256>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Example candidate images:\n",
      "\n",
      "Candidate 1:\n",
      "  Key: 003074d3897bbb36750a04ab4c4415b1\n",
      "  Image mode: L\n",
      "  Image size: (256, 256)\n",
      "  Unique pixel values: [  0 255]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQAAAAEACAAAAAB5Gfe6AAACp0lEQVR4nO3dwWoCMRgA4aT0/V85PaxVbAu97RfIzElBcHbM7r/RQucaZ/OhBTQF0AKaAmgBTQG0gKYAWkBTAC2gKYAW0BRAC2gKoAU0BdACmgJoAU0BtICmAFpAUwAtoCmAFtAUQAtoCqAFNAXQApoCaAFNAbSApgBaQFMALaApgBbQFEALaAqgBTQF0AKaAmgBTQG0gKYAWkBTAC2gKYAW0BRAC2gKoAU0BdACmgJoAU0BtICmAFpAUwAtoCmAFtAUQAtoCqAFNAXQApoCaAFNAbSApgBaQFMALaApgBbQFEALaAqgBTQF0AKaz7vfcL4/5f/ipBVw/1teH/r851V3cfwKKIAW0BRAC2gKoAU0BdACmuMDgFvhXW6CL45fARPtR6ffCF8cvwIKoAU0BdACmi0CzOHuDrYIICmAFtAUQAtojg8AtsN/AHfIGwSYY6wxJtof+lPg+8DXIuuAB5jr+cGTAjrA2xcyogAO8OMLKVDABriOf4455zUJ7i9gAzyOf6y1HrPw9kmgrwGvq+AydwM8wOsqYOagDtAUeHsKCuzww8jjqI2JPgXGjylwOz7Acwocuxd4PmwKNAWO2wv8uvLfPwn0KcApgBbQFEALaAqgBca4hp/6o7EtAkjUdngbjl8BBdACmgJoAU0BtICmAFpAUwAtoCmAFtAUQAtoCqAFNAXQApoCaAFNAbSApgBaQFMALaApgBbQFEALaAqgBTQF0AKaAmgBTQG0gKYAWkBTAC2gKYAW0BRAC2gKoAU0BdACmgJoAU0BtICmAFpAUwAtoCmAFtAUQAtoCqAFNAXQApoCaAFNAbSApgBaQFMALaApgBbQFEALaAqgBTQF0AKaAmgBTQG0gKYAWkBTAC2gKYAW0BRAC2gKoAU0BdACmuMDfAGSYDj/j5Wz+QAAAABJRU5ErkJggg==",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=256x256>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Candidate 2:\n",
      "  Key: 0031d7f23b834952f58ceb4449a06dd3\n",
      "  Image mode: L\n",
      "  Image size: (256, 256)\n",
      "  Unique pixel values: [  0 255]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQAAAAEACAAAAAB5Gfe6AAADBElEQVR4nO3d0W6bQBQAUaj6/7/sPiRVImrqaC32IO3MSxupjkfDDYUFnP2xrc0vLaApgBbQFEALaAqgBTQF0AKaAmgBTQG0gKYAWkBTAC2gKYAW0BRAC2gKoAU0BdACmgJoAU0BtICmAFpAUwAtoCmAFtAUQAtoCqAFNAXQApoCaAFNAbSApgBaQFMALaApgBbQFEALaAqgBTQF0AKaAmgBTQG0gKYAWkCzfIDf8L33bdv45zc0Afj9+RQsPwE7/iHcP/9kGk0A3w3jKWgCbjAB2wanYPkJmH8csL/+JzNZfgIKoAU05lzg+b6e7B2Wn4ACaAFNAbSApgBaQFMALaApgBbQFEALaAqgBTQF0AKaAmgBTQG0gMasCt/o6tDyE1AALaC5y/0BjOUnoABaQFMALaApgBbQFEALaAqgBTQF0AKaAmgBjX5u8Au0MLH8BLgVoX9XhntmSKAm4GP7P06/nsbyEyCvDH3f3g91tagJYO/8sf3Zz/5fmgD67je4StwEaAH9KSJNgBb4hO0NmgAt8G3bdzYosBPw0Nu/CUDrAc/PAMinSjUBN1kRYueFTcCNVoVbExTIO0WPM9CRoKB7hbWApgBaQFMALaApgBbQzAmwDyz6jrxmgOUnYMaR4MiZ/rTVgSbg8sgj674T14qbgIsTn98N+rUGfFwNnnoH6fITcO2VoeN/5fsPtufIa96gCbjwez87lHu1PUde8xZNwGXf+exQ/n/bc+Q1b7L8BBRAC2iu2wccj/J+cvV/5DVv0gSA99xP/9bV4fkUQAtoxD7g7Pmg7g8QqN8yc5PnRpsAdq/wcQb6jZOKe9wl1nODDnuXGH9utAng9wlevOr/miagO0UXpwBaQFMALaApgBbQFEALaAqgBTQF0AKaAmgBTQG0gKYAWkBTAC2gKYAW0BRAC2gKoAU0BdACmgJoAU0BtICmAFpAUwAtoCmAFtAUQAtoCqAFNAXQApoCaAFNAbSApgBaQFMALaApgBbQFEALaAqgBTQF0AKaAmgBzfIB/gDuGEsNH68gZwAAAABJRU5ErkJggg==",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=256x256>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Candidate 3:\n",
      "  Key: 004da87e4a1b99f87ce72ea54f8cd291\n",
      "  Image mode: L\n",
      "  Image size: (256, 256)\n",
      "  Unique pixel values: [  0 255]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQAAAAEACAAAAAB5Gfe6AAADm0lEQVR4nO3d227bMBQFUbHo//8y+xDHFiXKRYHyLMHZ81BHigGPxqSuAdr69rP5pQU0CaAFNAmgBTQJoAU0CaAFNAmgBTQJoAU0CaAFNAmgBTQJoAU0CaAFNAmgBTQJoAU0CaAFNAmgBTQJoAU0CaAFNAmgBTQJoAU0CaAFNAmgBTQJoAU0CaAFNAmgBTQJoAU0CaAFNAmgBTQJoAU0CaAFNAmgBTQJoAU0CaAFNAmgBTQJoAU0CaAFNAmgBTQJoAU0CaAFNAmgBTQJoAU0CaAFNAmgBTQJoAU0CaAFNAmgBTQJoAU0CaAFNAmgBTQJoAU0CaAFNAmgBTQJoAU0CaAFNL9LP619vdzpf7dqdTJtWLpLhLIAbdtv9LgkKQrQTtt7XmOoCTDd2nskKDkKtK1PNrUfdwuEigDt4pu+RYGCAFfbf4sZgE+Euh8C6wNcD4DtDgUKRsAdBvo1ywMcv+F2sxNCfzGE58D6AP/wHQ+jo9WUWR3gNAOOb+jD79p8YSHFU+DdNrX9G4aFlRQHmM2HNr607TX8CwpU7wQvT3/3g79N1q5CHAUOW9WP665+XkLtLbEHk2vwR4Vhl1hyjgBGwC0uAp+sDjD7FvtWOsvfU3ExNNLvNQbKp0B//NOGFY7lAf5yM4iPhJI7Qu/W68vBgrvC0+NZ27av2yE6ADkP2I1/vf01d4ROk+Aue8Ct6MHIcaDvgoxXw+DhmXgy1HaDou/esltx+vU6tbJng8+NabPTgEei6ctSik6Een9e5B+OfmOJPl9aiPj7gH5efIyK/j0/9ktrKTwV7uMT0jc3hx4/fuA9wd77a/734UVRfz+gjz+9do1b38fo00fq/x9yQ2R3kBuGwfek76/DwKccBQaeBQ63wLbdtC+7LV54FNh/6vn7/fATodPHTq4EP/lUePK5G9//f6GeDvebbD8bAbfB/30AJgG0gCYBtIAmAbSAJgG0gCYBtIAmAbSAJgG0gCYBtIAmAbSAJgG0gCYBtIAmAbSAJgG0gCYBtIAmAbSAJgG0gCYBtIAmAbSAJgG0gCYBtIAmAbSAJgG0gCYBtIAmAbSAJgG0gCYBtIAmAbSAJgG0gCYBtIAmAbSAJgG0gCYBtIAmAbSAJgG0gCYBtIAmAbSAJgG0gCYBtIAmAbSAJgG0gCYBtIAmAbSAJgG0gCYBtIAmAbSAJgG0gCYBtIAmAbSAJgG0gCYBtIAmAbSAJgG0gObHB/gDkYaE8bq2ae4AAAAASUVORK5CYII=",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=256x256>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# load images\n",
    "\n",
    "candidate_directory = Path(\"../../train/B\")\n",
    "reference_directory = Path(\"glossen\")\n",
    "\n",
    "print(\"Loading candidates...\")\n",
    "candidates = load_candidate_images(candidate_directory)\n",
    "print(\"Loading references...\")\n",
    "references = load_gold_images(reference_directory)\n",
    "\n",
    "print(\"Candidates:\", len(candidates))\n",
    "print(\"References:\", len(references))\n",
    "\n",
    "# 3 example outputs for loaded images\n",
    "print(\"\\nExample loaded images:\")\n",
    "for i, (key, img) in enumerate(list(references.items())[:3]):\n",
    "    print(f\"\\nReference {i+1}:\")\n",
    "    print(f\"  Key: {key}\")\n",
    "    print(f\"  Image mode: {img.mode}\")\n",
    "    print(f\"  Image size: {img.size}\")\n",
    "    print(f\"  Unique pixel values: {np.unique(np.array(img))}\")\n",
    "    display(img)\n",
    "\n",
    "print(\"\\nExample candidate images:\")\n",
    "for i, (key, img) in enumerate(list(candidates.items())[:3]):\n",
    "    print(f\"\\nCandidate {i+1}:\")\n",
    "    print(f\"  Key: {key}\")\n",
    "    print(f\"  Image mode: {img.mode}\")\n",
    "    print(f\"  Image size: {img.size}\")\n",
    "    print(f\"  Unique pixel values: {np.unique(np.array(img))}\")\n",
    "    display(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sarah\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\huggingface_hub\\file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cache directory: C:\\Users\\sarah\\AppData\\Local\\Temp/clip_cache\n",
      "Processing candidate images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2863/2863 [00:05<00:00, 545.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing reference images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3190/3190 [00:06<00:00, 506.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Calculating CLIP scores...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading features cache: 100%|██████████| 3190/3190 [00:02<00:00, 1147.37it/s]\n",
      "Loading features cache: 100%|██████████| 2863/2863 [00:02<00:00, 1212.40it/s]\n"
     ]
    }
   ],
   "source": [
    "def signwriting_to_clip_image(img):\n",
    "    if img.mode != 'RGB':\n",
    "        img = img.convert('RGB')\n",
    "    \n",
    "    # correct sizing for CLIP\n",
    "    if img.size != (224, 224):\n",
    "        img = img.resize((224, 224))\n",
    "    \n",
    "    return img\n",
    "\n",
    "# initialize clip score\n",
    "clip_score = SignWritingCLIPScore()\n",
    "candidate_keys = list(candidates.keys())\n",
    "\n",
    "print(\"Processing candidate images...\")\n",
    "candidate_images = [signwriting_to_clip_image(img) for img in tqdm(candidates.values())]\n",
    "print(\"Processing reference images...\")\n",
    "reference_images = [signwriting_to_clip_image(img) for img in tqdm(references.values())]\n",
    "\n",
    "print(\"\\nCalculating CLIP scores...\")\n",
    "all_scores = clip_score.score_all(reference_images, candidate_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3190/3190 [00:34<00:00, 91.49it/s] \n"
     ]
    }
   ],
   "source": [
    "# main comparison loop\n",
    "\n",
    "matches_dir = Path(\"score_matches\")\n",
    "matches_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "for i, (stem, scores) in tqdm(list(enumerate(zip(references.keys(), all_scores)))):\n",
    "    argmax = np.argmax(scores)\n",
    "    best_score = scores[argmax]\n",
    "    \n",
    "    # perfect match indicates empty image, skip\n",
    "    if best_score > 0.99:\n",
    "        if np.all(np.array(signwriting_to_clip_image(reference_images[i])) == 255):\n",
    "            continue\n",
    "    \n",
    "    side_by_side = create_side_by_side_comparison(\n",
    "        references[stem],\n",
    "        candidates[candidate_keys[argmax]],\n",
    "        best_score,\n",
    "        stem,\n",
    "        candidate_keys[argmax]\n",
    "    )\n",
    "    side_by_side.save(matches_dir / f\"{stem}_comparison.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=512x256>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|█████████▊| 3124/3190 [14:21<00:05, 11.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Manually accepted match for 09074\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3190/3190 [14:22<00:00,  3.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total matches found: 2797\n",
      "Total manual reviews: 298\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# final matching loop \n",
    "\n",
    "matches_dir = Path(\"matches\")\n",
    "matches_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "has_matches = 0\n",
    "manual_reviews = 0\n",
    "\n",
    "for i, (stem, reference) in enumerate(tqdm(list(references.items()), position=0, leave=True)):\n",
    "    scores = all_scores[i] \n",
    "    best_score_idx = np.argmax(scores)\n",
    "    best_score = scores[best_score_idx]\n",
    "    \n",
    "    # perfect match indicates empty image, skip\n",
    "    if best_score > 0.99:\n",
    "        if np.all(np.array(signwriting_to_clip_image(reference)) == 255):\n",
    "            continue\n",
    "    \n",
    "    save_match = False        \n",
    "    if 0.97 <= best_score < 0.98:  # manual review range\n",
    "        manual_reviews += 1\n",
    "        best_candidate_key = candidate_keys[best_score_idx]\n",
    "        best_candidate = candidates[best_candidate_key]\n",
    "        \n",
    "        review_result = manual_review(reference, best_candidate, best_score, stem, best_candidate_key)\n",
    "        if review_result:\n",
    "            save_match = True\n",
    "            has_matches += 1\n",
    "            print(f\"Manually accepted match for {stem}\")\n",
    "    elif best_score > 0.93:  # automatic acceptance threshold\n",
    "        save_match = True\n",
    "        has_matches += 1\n",
    "    \n",
    "    if save_match:\n",
    "        best_candidate_key = candidate_keys[best_score_idx]\n",
    "        best_candidate = candidates[best_candidate_key]\n",
    "        \n",
    "        side_by_side = create_side_by_side_comparison(\n",
    "            reference,\n",
    "            best_candidate,\n",
    "            best_score,\n",
    "            stem,\n",
    "            best_candidate_key\n",
    "        )\n",
    "        side_by_side.save(matches_dir / f\"{stem}.png\")\n",
    "\n",
    "print(f\"Total matches found: {has_matches}\")\n",
    "print(f\"Total manual reviews: {manual_reviews}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
